# Prompt 提示词

大语言模型的本质是预测引擎。接收一段顺序文本作为输入，然后基于训练数据预测下一个最可能出现的token。模型每预测一个token，并将其追加至输入序列末尾，再预测下一个token。每个token的预测都是基于之前已经预测的token序列。

写提示词时，其实就是在设法引导模型输出正确的token序列，提示词工程的目标：是设计出能驱动模型产生准确输出的高质量提示词。通常需要不断调试，包括优化提示词长度、语言风格和结构，以适配任务目标。在自然语言处理（NLP）和LLM应用场景中，提示词即模型生成响应或预测所依赖的输入

提示词可应用于多种任务，如文本摘要、信息抽取、问答、文本分类、语言或代码翻译、代码生成、代码文档生成或推理等

## LLM 输出配置

### 输出长度（Output Length）

输出长度即模型生成响应的token数，输出token越多，模型计算开销越大，响应时间也越慢，成本越高；缩短输出长度并不会让模型“输出的更简洁”，它只是在达到目标长度时停止。如果你想获得短内容输出，还需要通过提示词引导模型尽早收敛

### 采样控制（Sampling Control）

LLM并不是预测一个确定的token，而是对所有可能的下一个token给出概率分布，然后从中采样决定最终输出。控制采样方式的关键参数包含temperature和top_p、top_k

- temperature 控制采样的随机性（范围：0-1）
- Top-K 和 Top-P（又称核采样，nucleus sampling）控制采样时“候选 token 池”的范围

参数协同调优（Putting it all together）

在深度生成模型的世界里， temperature 和 top_p/top_k 参数是控制模型生成响应的重要参数。相互配合决定了模型输出的风格和质量。

在极端设定下，这些参数的微妙平衡会被道破：当temperature 设置为 0 时，所有精细选择瞬间失去意义，模型变得如同铁板一块，只会选择概率最高的token；反之，若 temperature 设置得极高（比如在 1 以上直至数值飙升至 10），那种混沌的随机性使得模型仿佛进入了狂欢模式，而 top-K 与 top-P 则仅仅成为了粗略的筛选手段；类似地，当 top-K 被压制至 1 时，其它参数都将黯然失色，因为只有唯一的 token 能够通过重重筛选；而当 top-K 数值飙至整个词汇表的规模时，任何概率非零的 token 都能通过考验，彻底失去了筛选的意义。top-P 参数也是如此：极低的 top-P 值几乎只允许最高概率的 token 存活，而 top-P 越接近 1，则所有微小的概率都将参与角逐。

对于输出风格的调控，我们通常给出一些建议以达成既定目标：若期望生成的文本既严谨连贯又带有适度创造性，temperature 可设在 0.2，top-P 定为 0.95，top-K 则设为 30；若渴求作品充满奇思妙想，那么可以将 temperature 提升到 0.9，top-P 调整为 0.99，而 top-K 则为 40；若想要较少创造性，可将 temperature 设为 0.1，top-P 设为 0.9，top-K 设为 20；而如果任务要求答案精确无误（如数学问题求解），那么直接将 temperature 设为 0，确保输出绝对确定。然而，随着这些参数的“自由度”增大，虽然能激发创造力，但也很容易导致输出内容走偏，甚至失焦。

小结：
temperature、top-K、top-P 与输出 token 数量之间互相影响，参数设置需要结合具体应用目标，并充分理解模型如何组合这些参数：
- 若temperature = 0，Top-K和top-E会被忽略
- 若top-K = 1,同样忽略top-P与temperature
- 若top-P 接近 0，模型通常只选取最高概率的 token，其他设置也被忽略

推荐初始值（通用型场景）：

- 中等创造力：temperature = 0.2，top-P = 0.95，top-K = 30
- 高创造力：temperature = 0.9，top-P = 0.99，top-K = 40
- 低创造力：temperature = 0.1，top-P = 0.9，top-K = 20
- 精确任务：temperature = 0，top-P = 任意，top-K = 任意（默认可用）

## 模型参数设置

- Temperature温度（范围0-1）：值越低，输出越确定；值越高，结果越多样、越随机，也就是说这可能会带来更多样化或更具创造性的产出；temperature = 0 代表贪婪解码（greedy decoding），总是选取概率最高的 token；值得注意的是，当多个 token 拥有相同最高概率时，即使 temperature 为 0，结果也可能不完全一致，取决于具体实现中的平局处理策略
- Top_p: 使用top_p,可以控制模型返回结果的确定性，如果需要准确和事实的答案，就把参数调低
- Top_k: 从概率最高的前 K 个 token 中采样。K 值越高，输出越丰富，越低则越稳重、趋于事实性。K=1 相当于贪婪解码（greedy decoding）
- Max Length：用来调整大模型生成的token数，指定max_length有助于防止大模型生成冗长或不相关的响应
- Stop Sequences：是一个字符串，可以阻止模型生成token，指定stop sequences是控制响应长度和结构的另一种方法
- Frequency Penalty（频率惩罚）：对于下一个生成的token进行惩罚，这个惩罚和 token 在响应和提示中已出现的次数成比例， frequency penalty 越高，某个词再次出现的可能性就越小，这个设置通过给 重复数量多的 Token 设置更高的惩罚来减少响应中单词的重复
- Presence Penalty（存在惩罚）：presence penalty 也是对重复的 token 施加惩罚，但与 frequency penalty 不同的是，惩罚对于所有重复 token 都是相同的。出现两次的 token 和出现 10 次的 token 会受到相同的惩罚。 此设置可防止模型在响应中过于频繁地生成重复的词。 如果您希望模型生成多样化或创造性的文本，您可以设置更高的 presence penalty，如果您希望模型生成更专注的内容，您可以设置更低的 presence penalty

与 temperature 和 top_p 一样，一般建议是改变 frequency penalty 和 presence penalty 其中一个参数就行，不要同时调整两个

## 提示词技巧（Prompting techniques）

大语言模型LLMs经过海量数据训练和指令调优，已具备理解用户提示Prompt并生成响应的能力。然而，LLMs并非完整，其输出质量很大程度上取决于输入提示的清晰度和精确性。提示越明确，模型预测后续文本的准确性就越高。此外，掌握并运用一系列针对LLMs训练方式和工作原理设计的特定提示技巧，能显著提升获取相关、高质量结果的可能性。

### 提示词格式

标准提示词应该遵循以下格式

```shell
<问题>？
或
<指令>
```

你可以将其格式化成问答格式(QA),这在许多问答数据集中是标准格式

```shell
Q:<问题>？
A:<回答>
```

#### 基础提示/零样本（General prompting/Zero-shot）

零样本提示是最基础、最直接的提示形式。他仅包含对任务的描述，有时会附带少量引导性文本供模型开始使用，而不提供任何具体的示例。输入可以多种多样，例如一个问题、一个故事的开头或一段操作指令

- 应用场景：适用于模型已通过预训练掌握、相对简单或常见的任务
- 关键点：对提示的清晰度和任务描述的准确性要求较高

#### 单样本/少样本提示（One-shot & Few-shot prompting）

在提示中提供示例是引导模型理解任务意图和期望输出格式的有效手段

- 单样本提示：提供一个完整的任务示例（输入+期望输出）。模型通过模仿这个范例来完成新的、类似的任务
- 少样本提示：提供多个（通常3-5个或更多，视任务复杂度和模型能力而定）任务示例。通过展示一系列输入和对应期望输出的模式，模型能更准确地学习并遵循这种模式
- 关键考量
  - 示例质量：示例必须高质量、准确无误且具有代表性。一个微小错误都可能会误导模型
  - 示例多样性：涵盖不同情况，特别是边缘案例（edge cases），有助于提升模型处理各种输入的健壮性（robust）
  - 示例数量：需在提供足够信息引导模型与避免超出模型输入长度限制之间取得平衡。

```text
<问题>?
<答案>
<问题>?
<答案>
<问题>?
<答案>
<问题>?
或
Q: <问题>?
A: <答案>
Q: <问题>?
A: <答案>
Q: <问题>?
A: <答案>
Q: <问题>?
A:
```

#### 系统、上下文与角色提示（System，Contextual，and Role prompting）

这三种提示都在引导LLM的行为，但侧重点不同，也可以相互结合：系统提示设定全局规则，角色提示塑造个性与风格，上下文提示提供即时具体信息。三者常结合使用，形成精细化控制模型输出的有力框架

系统提示
- 目的：设定模型的宏观行为框架、核心任务或总体约束。
- 应用：定义模型的基本功能（如：你是一个代码生成器）、强制输出特定格式（如json）、设定安全或风格基调（如：回答需保持尊重）
- 优势：有助于模型生成满足特定结构或规范要求（如API对接需要的JSON格式）的输出，限制不必要的发散（幻觉），并实施安全控制。

#### 角色提示 (Role Prompting)

- 目的：为模型分配一个特定的身份或角色（如经验丰富的资深前端开发）
- 应用：是模型生成符合该角色知识背景、口吻和行文风格的回应。可以指定具体的风格，如对抗性（confrontational）、描述性（descriptive）、直接（direct）、正式（formal）、幽默（humorous）、 有影响力（influential）、非正式（informal）、鼓舞人心（inspirational）、有说服力（persuasive）等
- 优势：极大提升输出的相关性、专业性和特定情境下的适切性（贴合度/契合度）

### 提示词要素

- 指令：想要模型执行的特定任务或指令
- 上下文：包含外部信息或额外的上下文信息，引导语言模型更好的响应
- 输入数据：用户输入的内容或问题
- 输出指示：指定输出的类型或格式

简单的示例：

```text
请将文本分为中性、否定或肯定
文本：我觉得食物还可以。
情绪:
```
